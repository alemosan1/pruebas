##
input {
    beats {
      port => 5044
    }
}

filter { 
	if [type] == "infosession_server" {
		grok { match => {"message" => "%{WORD:[@metadata][info_from]},%{UUID:unique_id}" } }
		
		kv { 
			field_split => ","
			target => "parsed_info"
		}
		
	    mutate { rename => { "parsed_info" => "%{[@metadata][info_from]}" } }
		
		# Hay que instalar este filtro :
		# bin/logstash-plugin install logstash-filter-aggregate
       	aggregate{
            task_id => "%{unique_id}"
            code => "event.to_hash.each do |key,value|
        				map[key] = value unless map.has_key?(key)
        				map[key] << value if map[key].is_a?(Array) and !value.is_a?(Array)
      				end"
      		push_previous_map_as_event => true
     		timeout => 5
     		timeout_tags => ['aggregated']
       	}

       	# Eliminamos las entradas individuales para quedarnos solo con la que tiene toda la info agrupada
	    if "aggregated" not in [tags] { drop {} } 

	} else if [type] == "infosession_client" {
		grok { match => { "message" => "%{UUID:unique_id}" } }
		
		kv { target => "parsed_info" }
	}

	mutate { remove_field => [ "beat", "@version", "offset", "host", "tags", "input_type", "message"] }
}

output {
	if [type] == "infosession_server" {
		elasticsearch {
			hosts => ["localhost:9200"]
			index => "infosession_server" #TODO: Poner nombre de sesion en la bd
		}
	} else if [type] == "infosession_client" {
		elasticsearch {
        	hosts => ["localhost:9200"]
		   	index => "infosession_client"
		}
	}
}

